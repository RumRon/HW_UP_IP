---
title: 'MUSA508 Final - Predict heroin overdose events to better allocate prevention resources'
author: "Jingyi Cai & Rui Jiang"
date: "12/5/2022"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---
```{r setup}
knitr::opts_chunk$set(message = FALSE, warning = FALSE , results='hide')
```
# 1. Background & Motivation

## 1.1 opioid overdose

In 2019, approximately 50,000 deaths occurred as a result of an opioid overdose. According to one study, bystanders were present at more than one-third of opioid overdose incidents. Bystanders with the necessary tools, such as naloxone, can intervene during an overdose and potentially save a life.

## 1.2 naloxone distribution

Arizona has an organization called Sonoran Prevention Works. They provided "Find free naloxone in Arizona" (https://spwaz.org/arizonanaloxone/). They include volunteers, syringe services programs, substance Use Treatment, substance use prevention coalition, recovery meeting, recovery housing, library, health department, food bank, emergency services, community health center, community based organization, church, behavioral health, and youth center as potential places to get naloxone when needed. However, Mesa only has three community medical services, and one syringe access program provides free naloxone to pick up. Our prediction will suggest new locations to set available naloxone for the public.

## 1.3 APP design
The APP will help public health officials to notice the possibility of a shortage of naloxone as a prevention resource for each provider (based on the prediction). It's also a tool that helps residents check the provider nearest them by navigating the map to their area. They could then contact the provider directly by phone to arrange a free naloxone pick-up.

## 1.4 Reference
1. National Institutes on Health: National Institute on Drug Abuse: Overdose Death Rates
https://www.drugabuse.gov/drug-topics/trends-statistics/overdose-death-rates

# 2.Data Manipulation and Visualization
In this section, we loaded necessary libraries, created plot theme options and map theme options, and identified functions of quintile breaks, and average nearest neighbor distance for further analysis.

```{r set_up, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  message = FALSE, warning = FALSE)

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt)   # for KDE and ML risk class intervals
library(mapview)
# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```


```{r read_mesa_data, results="hide", message =FALSE}

crimes <- st_read("https://data.mesaaz.gov/resource/qufy-tzv6.geojson") %>%
    filter(year == "2020") 

CouncilDistricts <- 
  st_read("https://data.mesaaz.gov/resource/4scp-vfkf.geojson") %>%
  st_transform(st_crs(crimes))%>%
  dplyr::select(District = district, name = districts)
  
# policeBeats <- 
#   st_read("https://data.cityofchicago.org/api/geospatial/aerh-rz74?method=export&format=GeoJSON") %>%
#   st_transform('EPSG:2223') %>%
#   dplyr::select(District = beat_num)
# 
# bothPoliceUnits <- rbind(mutate(policeDistricts, Legend = "Police Districts"), 
#                          mutate(policeBeats, Legend = "Police Beats"))


  
#socrata data download platform
mesaBoundary <- 
  st_read('https://data.mesaaz.gov/resource/qwhq-nske.geojson') %>%
  st_transform(st_crs(crimes))

```

## 2.1 A map of the outcome of interest 

This is a Heroin overdose map of Mesa in 2020.

```{r fig.width=6, fig.height=4, echo=FALSE, }
# uses grid.arrange to organize independent plots
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = mesaBoundary) +
  geom_sf(data = crimes, colour="red", size=0.1, show.legend = "point") +
  labs(title= "Opioid Overdose, Mesa - 2020") +
  mapTheme(title_size = 14),

ggplot() + 
  geom_sf(data = mesaBoundary, fill = "grey80") +
  stat_density2d(data = data.frame(st_coordinates(crimes)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Opioid Overdose") +
  mapTheme(title_size = 14) + theme(legend.position = "none"))
```

## 2.2 Creating a fishnet
Fishnet is one varying smoothly across the landscape, like elevation. The best way to represent this spatial trend in a regression-ready form, is to aggregate point-level data into a lattice of grid cells(Steif,2021).

```{r}
## using {sf} to create the grid
## Note the `.[mesaBoundary] %>% ` line. This is needed to clip the grid to our data
fishnet <- 
  st_make_grid(mesaBoundary,
               cellsize = 0.005,  # in meters 10
               square = TRUE) %>%
  .[mesaBoundary] %>%            # fast way to select intersecting polygons
  st_sf() %>%
  mutate(uniqueID = 1:n())


```


```{r }
## add a value of 1 to each crime, sum them with aggregate
crime_net <- 
  dplyr::select(crimes) %>% 
  mutate(countCrimes = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countCrimes = replace_na(countCrimes, 0),
         uniqueID = 1:n(),
         cvID = sample(round(nrow(fishnet) / 24),  #
                       size=nrow(fishnet), replace = TRUE))


```


## 2.3 Feature Selection
In the feature selection part, all the features were divided into three parts.Risk Factors, Amenities and ACS data.

**Risk Factors:**  From Broken Windows Theory, we search for some factors that can predict the overdose.
<p style="padding-left:2em;">
**trans_graffiti: **Graffiti abated with location. Sometimes graffiti means that the the area is messy.
**unsheltered: **Homeless usually stay in unsheltered places, and homeless are more likely to overdose. So in such places more likely to have a heroin overdose.  
**police_incidence: **Incidents based on initial police reports taken by officers when responding to calls for service. Heroin overdose often occurs in conjunction with other types of crime.  
**pol_dispatch: **Calls for service dispatched to Mesa Police Patrol Officers. Calls are modified for public use, obfuscating the address number through rounding it to the 100 block. This is related to those who would call for police.  
**code_violation: ** both Code Violations as determined by City of Mesa and reported complaints only, but no code violation found.   
</p>


**Amenities: **
<p style="padding-left:2em;">
**light: **Generally, places without lights overdose are more likely to happen.  
**park: **Parks are also the places overdose are more likely to happen.  
**railstation: **Rait stations are the places overdose are more likely to happen.  
</p>

```{r , results='hide', cache = TRUE}
## only pulling a single variable for our model to keep it simple
## using Socrata again
trans_graffiti <- 
  read.socrata("https://data.mesaaz.gov/Transportation/Transportation-Graffiti/9spb-749m")
trans_graffiti <- trans_graffiti %>%
    mutate(year = year_reported) %>% filter(year == 2018) %>%
    dplyr::select(Y = lat, X = lon) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "graffiti")

unSheltered <- 
  read.socrata("https://data.mesaaz.gov/Community-Services/Unsheltered-Point-in-Time-PIT-Count-Phoenix-Metro-/jagk-fkkw")
unSheltered <- unSheltered %>%
    filter(reporting_year == "2018") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "unSheltered")



## Neighborhoods to use in LOOCV in a bit
neighborhoods <- 
  st_read("https://raw.githubusercontent.com/RumRon/MUSA508/main/Final/data/Mesa_Neighborhoods_HOAs.geojson") %>%
  #https://raw.githubusercontent.com/RumRon/MUSA508/main/Final/data/Mesa_Neighborhoods_HOAs.geojson
  st_transform(st_crs(fishnet)) 

```

```{r other_factors, cache=TRUE}
police_incidence <- 
  read.socrata("https://data.mesaaz.gov/Police/Police-Incidents/39rt-2rfj")
police_incidence <- police_incidence %>%
    filter(report_year == "2020") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "pol_inci")


pol_dispatch <-
  read.socrata("https://data.mesaaz.gov/Police/Police-Computer-Aided-Dispatch-Events/ex94-c5ad")
pol_dispatch <- pol_dispatch%>% 
  filter(creation_year == "2020") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "pol_dsp")

code_violation <-
  read.socrata("https://data.mesaaz.gov/Code-Compliance/Code-Violations/ears-rpf9")
code_violation <- code_violation %>%
    filter(year_violation_closed == "2020") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Code_Violations")

light <-
  read.socrata("https://data.mesaaz.gov/Transportation/Streetlight-Fixtures/jrtd-htue")
light <-light %>%
  dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "lights")

# Amenities
park <-
  read.socrata("https://data.mesaaz.gov/Parks-Recreation-and-Community-Facilities/Parks-Locations-And-Amenities/djym-pkpp")
park <- park %>%
    #filter(year_violation_closed == "2020") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "park")

rail_station <-
  st_read("https://raw.githubusercontent.com/RumRon/MUSA508/main/Final/data/LightRailStation.geojson")%>%
  dplyr::select(geometry)%>%
  mutate(Legend = "light_rail")
```

**ACS: **Some factors, such as income and rent, are correlated with Heroin overdose. So, we loaded some ACS data to help us predict the overdose.
<p style="padding-left:2em;">
**•	Whites:** White population in each census tract  
**•	MedHHInc:** Median household income in each census tract. Important factor, the low-income citizen are more likely to overdose.  
**•	MedRent:** Median Rent for properties in each census tract.Important factor, there might be more overdose in  low-rent area.
**•	TotalPoverty:** Population living under the level of poverty in each census tract  
**•	TotalUnit:** Total housing units in each census tract  
**•	pctWhite:** white population proportion in each census tract  
**• pctBachelors:** Bachelor population proportion in each census tract  
**•	pctPoverty:** Poverty population proportion in each census tract  
**•	pctTotalVacant: **Vacant unites proportion in each census tract  
</p>

```{r ACS, cache=TRUE}
acs_variable_list.20 <- load_variables(2020, #year
                                         "acs5", #five year ACS estimates
                                         cache = TRUE)
tracts20 <- 
  get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B15001_050E",
                                             "B15001_009E","B19013_001E","B25058_001E",
                                             "B06012_002E","B28010_007E","B08101_001E",
                                             "B09001_001E","B09001_003E","B09021_002E",
                                             "B11001I_001E", "B14001_009E",
                                             "B17001_002E","B27001_001E","B18101_001E",
                                             "B19001_001E","B25001_001E","B25040_001E"), 
          year=2020, state= "AZ", county= "Maricopa", geometry=T, output="wide") %>%
  st_transform('EPSG: 4326') %>%
  rename(TotalPop = B25026_001E, 
         Whites = B02001_002E,
         FemaleBachelors = B15001_050E, 
         MaleBachelors = B15001_009E,
         MedHHInc = B19013_001E, 
         MedRent = B25058_001E,
         TotalPoverty = B06012_002E,
         Nocom = B28010_007E, 
         Waytowork = B08101_001E,
         Popunder18 = B09001_001E, 
         Popunder3 = B09001_003E,
         Singleadult = B09021_002E, 
         Householdtype = B11001I_001E,
         Addmittogra = B14001_009E,
         Poverty  = B17001_002E,
         Healthins  = B27001_001E,
         Disable  = B18101_001E,
         Familyincome  = B19001_001E,
         Housingunits  = B25001_001E,
         Househeatingfuel  = B25040_001E)%>%
  mutate(pctWhite = ifelse(TotalPop > 0, Whites / TotalPop,0),
         pctBachelors = ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop),0),
         pctPoverty = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0),
         year = "2020") 
```

```{r city_boundary, cache=TRUE}
city_boundary <-
  st_read("https://raw.githubusercontent.com/RumRon/MUSA508/main/Final/data/Mesa%20Census%20Tracts%20To%20City%20Boundary.geojson")%>%
  st_transform('EPSG:4326') %>%
  #dplyr::select(geoid)%>%
  rename(GEOID = geoid)

ACS_mesa  <-left_join(city_boundary,st_drop_geometry(tracts20), by = "GEOID")
Income <- ACS_mesa%>%
  dplyr::select(geometry, MedHHInc)%>%
  mutate(Legend = 'MedInc')
 # st_sf(sf_column_name = 'geometry.x')
```

## 2.4 Aggregate features to our fishnet

```{r, cache=TRUE}
vars_net <- 
  rbind(trans_graffiti,unSheltered,police_incidence, code_violation, park, pol_dispatch, light,rail_station) %>%
  st_join(fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>%
  summarize(count = n()) %>% #important
  left_join(fishnet, ., by = "uniqueID") %>%
  spread(Legend, count, fill=0) %>%
  dplyr::select(-`<NA>`) %>%
  na.omit() %>%
  ungroup()
```

```{r}
ACS2 <- ACS_mesa%>%
  dplyr::select(pctWhite, pctBachelors, pctPoverty, MedHHInc, MedRent, Familyincome)
ACS1 <- ACS2 %>%
  dplyr::select(geometry, pctWhite, pctBachelors, pctPoverty,  MedHHInc, MedRent,Familyincome)
```

```{r}
vars_net<- vars_net %>%
  st_join(ACS1)
```

Here are the risk factors divided by Fishnet. We can find that some factors, such as code violations and unsheltered places, are related to overdose.

```{r}
vars_net.long <- 
  gather(vars_net, Variable, value, -geometry, -uniqueID)

vars <- unique(vars_net.long$Variable)
mapList <- list()

for(i in vars){
  mapList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(vars_net.long, Variable == i), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme()}

do.call(grid.arrange,c(mapList, ncol=4,nrow=4, top="Risk Factors by Fishnet"))
```

### 2.4.1 For risk and amenity factors:  k nearest fishnet facotrs
Then, we can use the nn_function to measure the distance from the centroid of each fishnet to different factors.After calculating the distance, we can join NN feature to our fishnet.

```{r}
st_c <- st_coordinates
st_coid <- st_centroid
test1<-st_c(st_coid(vars_net))
test2<- st_c(unSheltered)
test3 <- st_c(trans_graffiti)
test_incidence <-st_c(police_incidence)
test_code <- st_c(code_violation)
test_park <- st_c(park)
test_disp <- st_c(pol_dispatch)
test_light <- st_c(light)
test_station <- st_coid(rail_station)%>% st_c()

## create NN from abandoned cars
vars_net <- vars_net %>%
    mutate(
      Un_Sheltered.nn =
        nn_function(test1, test2,k=3),
      Trans_graffiti.nn =
        nn_function(test1, test3,k=3),
      Plc_incidence.nn = 
        nn_function(test1, test_incidence,k=3),      
      Plc_dispatch.nn = 
        nn_function(test1, test_disp, k=3),
      Code_violation.nn = 
        nn_function(test1, test_code,k=3),
      Park.nn = 
        nn_function(test1, test_park,k=3),
      Light.nn = 
        nn_function(test1, test_light, k=3),
      Rail_station.nn = 
        nn_function(test1, test_station, k =3))
     
```


```{r}
## Visualize the NN feature
vars_net_nn <-
  dplyr::select(vars_net, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

ggplot() +
      geom_sf(data = vars_net_nn, aes(fill=value), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Visualize the NN feature") +
      facet_wrap(~Variable) +
      mapTheme()

```


```{r}
## important to drop the geometry from joining features
final_net <-
  left_join(crime_net, st_drop_geometry(vars_net), by="uniqueID") 

```

### 2.4.2 Join in areal data
Many of the areas in neighborhood data in MESA is missing, so in this model we use the council districts data to ensure intagrety.
```{r}
final_net <-
  st_centroid(final_net) %>%
    st_join(dplyr::select(CouncilDistricts, name)) %>%  # if touch, add name
    #st_join(dplyr::select(CouncilDistricts, District), by = "uniqueID") %>%
      st_drop_geometry() %>%
      left_join(dplyr::select(final_net, geometry, uniqueID)) %>%
      st_sf() 
  #na.omit()

# for live demo
#mapview::mapview(final_net, zcol = "name.x")
```


```{r}
## generates warnings from PROJ issues
## {spdep} to make polygon to neighborhoods... 
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
## ... and neighborhoods to list of weigths
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE) 

#print(final_net.weights, zero.policy=TRUE)
```


# 3. Exploring the spatial process of heroin overdose
## 3.1 Local Moran’s I-related
This figure describes the local spatial process of heroin overdose. The smaller p-values represent spatial clustering, and we can find spatial clustering trends in west part of Mesa. This part is also the center city of Mesa. Plus, there are some smaller hotspots in the middle of Mesa. We should explore it further with geospatial characteristics in Mesa.

```{r}
## see ?localmoran
local_morans <- localmoran(final_net$countCrimes, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()



# join local Moran's I results to fishnet
final_net.localMorans <- 
  cbind(local_morans, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(crime_count = countCrimes, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Sig_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)
  
```


```{r}
## This is just for plotting
vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme(title_size = 14) + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Crimes"))
```

```{r}
# generates warning from NN
final_net <- final_net %>%
  mutate(crime.isSig =
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>%
  mutate(crime.isSig.dist =
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net,
                                           crime.isSig == 1))),
                       k = 1))


```


We can plot NN distance to hot spot. For the west part, which is the center city of Mesa, the significant distance is shorter, which means a high rate of overdose.

```{r }
ggplot() +
      geom_sf(data = final_net, aes(fill=crime.isSig.dist), colour=NA) +
      scale_fill_viridis(name="significant distance") +
      labs(title="distance to highly significant hot pot") +
      mapTheme()
```

## 3.2 Modeling and CV
Cross-validation ensures that the goodness of fit results for a single hold out is not a fluke.In this part, we will build our model and cross-validate them.

```{r, results='hide', message =FALSE, warning = FALSE,  }

# View(crossValidate)

## define the variables we want
reg.ss.vars <- c("Un_Sheltered.nn","Trans_graffiti.nn","crime.isSig.dist", "Plc_incidence.nn", "Plc_dispatch.nn", "Code_violation.nn", "Park.nn", "Light.nn", "Rail_station.nn","pctWhite", "pctBachelors", "pctPoverty", "MedHHInc", "MedRent", "Familyincome")
## RUN REGRESSIONS
reg.ss.spatialCV <- crossValidate(
  dataset = final_net%>%na.omit(),
  id = "name",                           
  dependentVariable = "countCrimes",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = name, countCrimes, Prediction, geometry)
```
Table of MAE and standard deviation MAE by regression.
If the model generalized well, the distribution of errors would cluster tightly together. For the second figure, we can find that the MAE for the second district is higher than other districts, so in further improvement we should pay more attention to this part.



## 3.3 Scatterplot with correlations

```{r}
correlation.long <-
  st_drop_geometry(final_net) %>%
    dplyr::select(-uniqueID, -cvID, -name) %>%
    gather(Variable, Value, -countCrimes)

correlation.cor <-
  correlation.long %>%
    group_by(Variable) %>%
    summarize(correlation = cor(Value, countCrimes, use = "complete.obs"))
    
ggplot(correlation.long, aes(Value, countCrimes)) +
  geom_point(size = 0.1) +
  geom_text(data = correlation.cor, aes(label = paste("r =", round(correlation, 2))),
            x=-Inf, y=Inf, vjust = 1.5, hjust = -.1) +
  geom_smooth(method = "lm", se = FALSE, colour = "black") +
  facet_wrap(~Variable, ncol = 6, scales = "free") +
  labs(title = "Overdose count as a function of risk factors") +
  plotTheme()
```

To explore it further, we extract two factors with high slopes and zoom into them. From this figure, we can see that the farther a place is from code violation and unsheltered places, the less likely it is that heroin overdose will occur. So, some kinds of the risk facotrs are useful.

```{r shelter}
special_factor <- correlation.long%>%filter(Variable =="Un_Sheltered.nn" | Variable =="Code_violation.nn")
spe.cor <-
  special_factor %>%
    group_by(Variable) %>%
    summarize(correlation = cor(Value, countCrimes, use = "complete.obs"))


ggplot(special_factor, aes(Value, countCrimes)) +
  geom_point(size = 0.1) +
  geom_text(data = spe.cor, aes(label = paste("r =", round(correlation, 2))),
            x=-Inf, y=Inf, vjust = 1.5, hjust = -.1) +
  geom_smooth(method = "lm", se = FALSE, colour = "red") +
  facet_wrap(~Variable, ncol = 2, scales = "free") +
  labs(title = "Crime count as a function of risk factors") +
  plotTheme()
```
```{r}
final_net2 <- final_net[!is.na(final_net$name),]
```


## 3.4. Cross-Validation


Geospatial risk models are purely spatial, so spatial cross-validation becomes an important option. A well generalized crime predictive model learns the crime risk ‘experience’ at both citywide and local spatial scales. The best way to test for this is to hold out one local area, train the model on the remaining n - 1 areas, predict for the hold out, and record the goodness of fit. In this form of spatial cross-validation called ‘Leave-one-group-out’ cross-validation (LOGO-CV), each neighborhood takes a turn as a hold-out.

After Cross-validation, we can find something about accuracy and generalizability. 

```{r  results="hide", message = FALSE, warning=FALSE, cache=TRUE}
reg.vars <- c("Un_Sheltered.nn","Trans_graffiti.nn","crime.isSig.dist", "Plc_incidence.nn", "Plc_dispatch.nn", "Code_violation.nn", "Park.nn", "Light.nn", "Rail_station.nn","pctWhite", "pctBachelors", "pctPoverty", "MedHHInc", "MedRent", "Familyincome")

reg.ss.vars <- c("Un_Sheltered.nn","Trans_graffiti.nn","crime.isSig.dist", "Plc_incidence.nn", "Plc_dispatch.nn", "Code_violation.nn", "Park.nn", "Light.nn", "Rail_station.nn","pctWhite", "pctBachelors", "pctPoverty", "MedHHInc", "MedRent", "Familyincome")

reg.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countCrimes",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, countCrimes, Prediction, geometry)

reg.ss.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countCrimes",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = cvID, countCrimes, Prediction, geometry)
  
reg.spatialCV <- crossValidate(
  dataset = final_net2,
  id = "name",
  dependentVariable = "countCrimes",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = name, countCrimes, Prediction, geometry)

reg.ss.spatialCV <- crossValidate(
  dataset = final_net2,
  id = "name",
  dependentVariable = "countCrimes",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = name, countCrimes, Prediction, geometry)
```

## 3.5 Accuracy
A host of goodness of fit metrics are calculated below with particular emphasis on generalizability across space. For k-fold cv model, there are some errors larger than 0.8, which is too larger for this model. Comparing the distribution of MAE, we can find that the Spatial Process features seem to reduce MAE a lot, and make the model more accurate. 

```{r   message = FALSE, warning=FALSE}
reg.summary <- 
  rbind(
    mutate(reg.cv,           Error = Prediction - countCrimes,
                             Regression = "Random k-fold CV: Just Risk Factors"),
                             
    mutate(reg.ss.cv,        Error = Prediction - countCrimes,
                             Regression = "Random k-fold CV: Spatial Process"),
    
    mutate(reg.spatialCV,    Error = Prediction - countCrimes,
                             Regression = "Spatial LOGO-CV: Just Risk Factors"),
                             
    mutate(reg.ss.spatialCV, Error = Prediction - countCrimes,
                             Regression = "Spatial LOGO-CV: Spatial Process")) %>%
    st_sf() 

error_by_reg_and_fold <- 
  reg.summary %>%
    group_by(Regression, cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countCrimes, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
    facet_wrap(~Regression) +  
    geom_vline(xintercept = 0) + scale_x_continuous(breaks = seq(0, 8, by = 0.2)) + 
    labs(title="Distribution of MAE", subtitle = "k-fold cross validation vs. LOGO-CV",
         x="Mean Absolute Error", y="Count") +
    plotTheme()
```

As the table shows, the MAE of the model with spatial process and just risk model are the same because there are too few areas to see a clear difference from the graph(we just have 6 coucuil districts). But the spatial process is still an important part in our model.

```{r MAE,   message = FALSE, warning = FALSE, results='asis'}
st_drop_geometry(error_by_reg_and_fold) %>%
  group_by(Regression) %>% 
    summarize(Mean_MAE = round(mean(MAE), 2),
              SD_MAE = round(sd(MAE), 2)) %>%
  kable() %>%
    kable_styling("striped", full_width = F) %>%
    row_spec(2, color = "black", background = "#FDE725FF") %>%
    row_spec(4, color = "black", background = "#FDE725FF") 
```

We can plot a table to explain this kind of spatial process. As the table shows, with spatial process, the p-value dropped, which means that spatial process features helped account for the spatial variation in heroin overdose.

```{r }
neighborhood.weights <-
  filter(error_by_reg_and_fold, Regression == "Spatial LOGO-CV: Spatial Process") %>%
    group_by(cvID) %>%
      poly2nb(as_Spatial(.), queen=TRUE) %>%
      nb2listw(., style="W", zero.policy=TRUE)

a <- filter(error_by_reg_and_fold, str_detect(Regression, "LOGO"))  %>% 
    st_drop_geometry() %>%
    group_by(Regression) %>%
    summarize(Morans_I = moran.mc(abs(Mean_Error), neighborhood.weights, 
                                 nsim = 99, zero.policy = TRUE, 
                                 na.action=na.omit)[[1]],
              p_value = moran.mc(abs(Mean_Error), neighborhood.weights, 
                                 nsim = 99, zero.policy = TRUE, 
                                 na.action=na.omit)[[3]])

```


```{r, results='asis'}
kable(a)%>%
    kable_styling("striped", full_width = F) 
```

## 3.6 Generalizability
### 3.6.1 CV for different districts
Will each council be the same for the LOGO-CV Regression Model? We can check it for generalizability. 

As the figure shows, the MAE is higher in second council district in Mesa. To further explain it, we should do more researches on Mesa's background.

```{r , cache=TRUE}
error_by_reg_and_fold %>%
  filter(str_detect(Regression, "LOGO")) %>%
  ggplot() +
    geom_sf(aes(fill = MAE)) +
    facet_wrap(~Regression) +
    scale_fill_viridis() +
    labs(title = "Overdose errors by LOGO-CV Regression") +
    mapTheme() + theme(legend.position="bottom")
```
```{r}
# calculate errors by council district
error_by_reg_and_fold <- 
  reg.ss.spatialCV %>%
    group_by(cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countCrimes, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>% 
  arrange(desc(MAE))
error_by_reg_and_fold %>% 
  arrange(MAE)

## plot histogram of OOF (out of fold) errors
error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
  scale_x_continuous(breaks = seq(0, 11, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "LOGO-CV",
         x="Mean Absolute Error", y="Count") 

ggplot(error_by_reg_and_fold)+
  geom_point(aes(x= cvID, y = MAE))+
  labs(title="MAE for each District",
       x="District", 
       y="MAE")+
  plotTheme()
```


### 3.6.2 Generalizability by Race

Race is also an important factor to predict the heroin overdose. So, race can be used to test our model. We divide Mesa into two parts. If the percentage of white is larger than 50%, it is a Majority White tract. 

```{r}
race_test <- ACS_mesa %>% 
  mutate(raceContext = ifelse(pctWhite > .5, "Majority_White", "Majority_Non_White")) %>%
  .[CouncilDistricts,]%>%
  dplyr::select(raceContext)%>%
  na.omit

```

As the table shows, race don't have much effect on our model, but the model works better for white districts. The similarity for the race results of two models might because in this case we used the council districts of Mesa, which is too big for spatial LOGO-CV.  
Plus, Mesa is a predominantly white city, so the race factor do not work for this city.

```{r plotmesa, cache=TRUE}
ggplot() + 
  geom_sf(data = race_test, aes(fill = raceContext)) +
  #geom_sf(data = crimes, colour="red", size=0.1, show.legend = "point") +
  labs(title= "Race in Mesa") +
  mapTheme(title_size = 14)
```

```{r fit,   message = FALSE, warning = FALSE, results='asis'}
reg.summary %>% 
  filter(str_detect(Regression, "LOGO")) %>%
    st_centroid() %>%
    st_join(race_test) %>%
    na.omit() %>%
      st_drop_geometry() %>%
      group_by(Regression, raceContext) %>%
      summarize(mean.Error = round(mean(Error, na.rm = T),3)) %>%
      spread(raceContext, mean.Error) %>%
      kable(caption = "Mean Error by neighborhood racial context") %>%
        kable_styling("striped", full_width = F)  
```



# 4. Prediction
## 4.1 Get 2021 over dose
As we referred before, 2021 overdose data is the test data. Let's load them.

```{r crime21, cache=TRUE}
crimes21 <- 
  crimes <- st_read("https://data.mesaaz.gov/resource/qufy-tzv6.geojson") %>%
  filter(year == "2021") %>%
  st_transform(st_crs(crimes)) %>%
  .[fishnet,]
```


```{r}
ml_breaks <- classIntervals(reg.ss.spatialCV$Prediction, 
                             n = 5, "fisher")
crime_risk_sf <-
  reg.ss.spatialCV %>%
  mutate(label = "Risk Predictions",
         Risk_Category =classInt::findCols(ml_breaks),
         Risk_Category = case_when( 
           #Risk_Category == NA ~ "0",
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(crimes21) %>% mutate(crimeCount = 1), ., sum) %>%
      mutate(crimeCount = replace_na(crimeCount, 0))) %>%
  dplyr::select(label,Risk_Category, crimeCount)


crime_risk_sf[is.na(crime_risk_sf)] <- 0
```


## 4.2 Kernel Density Prediction
For kernel density prediction, we can also find that the west part is the main place for heroin overdose.
For the city scale of Mesa, we use 300 Ft as the basic legend number. As the picture shows, the scale of 300 Ft works best for the model.
However, compared with the previous case Chicago, Mesa city is too small to distinguish with the difference between different levels in kernel density prediction. So the legend level of this figure may not be clear enough, but we can still find the density distribution trend in Mesa. 

```{r}
# demo of kernel width
crime_ppp <- as.ppp(st_coordinates(crimes), W = st_bbox(final_net))
crime_KD.1000 <- spatstat.core::density.ppp(crime_ppp, 300)
crime_KD.1500 <- spatstat.core::density.ppp(crime_ppp, 600)
crime_KD.2000 <- spatstat.core::density.ppp(crime_ppp, 900)
crime_KD.df <- rbind(
  mutate(data.frame(rasterToPoints(mask(raster(crime_KD.1000), as(CouncilDistricts, 'Spatial')))), Legend = "300 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(crime_KD.1500), as(CouncilDistricts, 'Spatial')))), Legend = "600 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(crime_KD.2000), as(CouncilDistricts, 'Spatial')))), Legend = "900 Ft.")) 

crime_KD.df$Legend <- factor(crime_KD.df$Legend, levels = c("300 Ft.", "600 Ft.", "900 Ft."))

ggplot(data=crime_KD.df, aes(x=x, y=y)) +
  geom_raster(aes(fill=layer)) + 
  facet_wrap(~Legend) +
  coord_sf(crs=st_crs(final_net)) + 
  scale_fill_viridis(name="Density") +
  labs(title = "Kernel density with 3 different search radii") +
  mapTheme(title_size = 14)
```

```{r}
as.data.frame(crime_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
   ggplot() +
     geom_sf(aes(fill=value)) +
     geom_sf(data = sample_n(crimes, 200), size = .5) +
     scale_fill_viridis(name = "Density") +
     labs(title = "Kernel density of 2020 crimes") +
     mapTheme(title_size = 14)
```
```{r}
crime_KDE_sum <- as.data.frame(crime_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) 
kde_breaks <- classIntervals(crime_KDE_sum$value, 
                             n = 5, "fisher")
crime_KDE_sf <- crime_KDE_sum %>%
  mutate(label = "Kernel Density",
         Risk_Category = classInt::findCols(kde_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(crimes21) %>% mutate(crimeCount = 1), ., sum) %>%
    mutate(crimeCount = replace_na(crimeCount, 0))) %>%
  dplyr::select(label, Risk_Category, crimeCount)
```

## 4.3 Comparison of Kernel Density and Risk Predictions
After the comparison, it is possible to identify more precisely where heroin overdoses are taking place, and there is a stronger focus from the figure.
```{r}
rbind(crime_KDE_sf, crime_risk_sf) %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = sample_n(crimes21, 276), size = .5, colour = "black") +
    facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2020 crime risk predictions; 2021 crimes") +
    mapTheme(title_size = 14)
```

The bar plot can show if the model make sense.
The risk prediction model narrowly edges out the Kernel Density in the highest risk categories - suggesting this simple model has some value relative to the business-as-usual hot spot approach. So to some extent, the model is better than the kernel Density prediction model.

```{r }
rbind(crime_KDE_sf, crime_risk_sf) %>%
  st_drop_geometry() %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category) %>%
  group_by(label, Risk_Category) %>%
  summarize(countCrimes = sum(Value)) %>%
  ungroup() %>%
  group_by(label) %>%
  mutate(Pcnt_of_test_set_crimes = countCrimes / sum(countCrimes)) %>%
    ggplot(aes(Risk_Category,Pcnt_of_test_set_crimes)) +
      geom_bar(aes(fill=label), position="dodge", stat="identity") +
      scale_fill_viridis(discrete = TRUE, name = "Model") +
      labs(title = "Risk prediction vs. Kernel density, 2021 crimes",
           y = "% of Test Set crimes (per model)",
           x = "Risk Category") +
  theme_bw() +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.5))
```


# 5. Conclusion
## 5.1 Bias for the model
We must know that the Geospatial risk model is based on the **Broken Windows Theory**, which is biased. A geospatial risk prediction model borrows the heroin overdose experience in places where it has been observed and tests whether that experience generalizes to places where risk may be high, despite few actual events. It’s pretty sure the model suffers from some level of bias. If law enforcement systematically over-polices certain communities, and this selection criteria goes unaccounted for in the model, then the model may be biased regardless of the above tests.

In other words, if the data inputs to a forecasting model are biased against communities of color, then the prediction outputs of that model will also be biased against those places. This bias compounds when risk predictions are converted to resource allocation. Surveillance increases, more crimes are ‘reported’, and more risk is predicted.

In our model, for the bias of heroin overdose, there are two main kinds of bias:  

<p style="padding-left:2em;">

**Reported Bias** We used the reported heroin overdose data. However, more crimes are ‘reported’, and more risk is predicted. Some areas may simply have more reports of heroin overdoses due to more surveillance, rather than a high number of heroin overdoses in the area itself.  

**Observation Bias**  heroin overdose are often unobserved because somebody overdosing on heroin  is frequently not arrested or sent to hospital - we only observe the event when there is an incident or a police presence.

</p>  

## 5.2 Improvement and App Instruction
To improve the model, we could find factors from more categories in the future, such as hospitals and schools, which could describe how the communities look like. New data will also need to be added; project progress and improvement results also need to be monitored so that the model can be adjusted for greater accuracy.

We recommend, based on the prediction map, distributing more naloxone to syringe services programs, substance Use Treatment, substance use prevention coalitions, recovery meetings, recovery housing, library, health department, food bank, emergency services, community health centers, community-based organizations, church, behavioral health, and youth center on those high probability areas. If some areas don't have the facilities described above, Sonoran Prevention Works could help to find volunteers. 

An APP named Naloxone Distribution Project (NDP) Helper will be designed to help public health officials notice the possibility of a shortage of naloxone as a prevention resource for each provider (based on the prediction). It's also a tool that helps residents check the provider nearest them by navigating the map to their area. They could then contact the provider directly by phone to arrange a free naloxone pick-up. Detailed UI will be shown in the video.

## 5.3 Yotube link
https://youtu.be/d-j08CwL-ZE


