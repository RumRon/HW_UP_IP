---
title: "Predicting Housing Prices for Mecklenberg County, NC - MUSA508 Midterm"
author: "Rui Jiang, Jingyi Cai"
date: '2022-09-25'
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup}
#set some global options for knitting chunks

#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(
	warning = FALSE,
	message = FALSE
)
# Load some libraries

library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(tidycensus)
library(geojsonio)
library(stargazer)
library(utils)
library(rgdal)
library(plyr)

# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")

```


```{r read_data, echo=TRUE}
primary.data<-
  st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")%>%
  st_transform('EPSG:2264')
```

```{r read_taxdata, eval=FALSE, include=FALSE}
tax.data<-
  st_read("/Users/rui/Documents/GitHub/MUSA_508/Midterm/parcel_taxdata/Parcel_TaxData.shp") %>%
  st_transform('EPSG:2264')

```


```{r split_data, include=FALSE}
primary.data<-
  primary.data%>%
  filter(price<10000000)

mklb.sf <- 
  primary.data %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 2264, agr = "constant") %>%
  st_transform('EPSG:2264') %>%
  mutate(storyheigh = as.numeric(gsub(" STORY", "", primary.data$storyheigh))
  )

mklb.sf<-
  mklb.sf %>%
  mutate(age=2022-yearbuilt,prisqft =price/heatedarea)%>%
  dplyr::select(commonpid,price,age,storyheigh,heatedarea,numfirepla,totalac,
                fullbaths,halfbaths,bedrooms,units,toPredict,prisqft)

numericVars <- 
  select_if(st_drop_geometry(mklb.sf), is.numeric) %>% na.omit()  

```



```{r read amentity data}

#school data
cmpd_school<-
  st_read('https://raw.githubusercontent.com/RumRon/MUSA_508/main/Midterm/geojson/CMS_Schools.geojson') %>%
  st_transform('EPSG:2264')

# firestation
cmpd_firestation<-
  st_read('https://raw.githubusercontent.com/RumRon/MUSA_508/main/Midterm/geojson/CFD_FireStations.geojson') %>%
  st_transform('EPSG:2264')

# church
cmpd_church<-
  st_read('https://raw.githubusercontent.com/RumRon/MUSA_508/main/Midterm/geojson/Churches.geojson') %>%
  st_transform('EPSG:2264')

# medical facilities
cmpd_medical<-
  st_read('https://raw.githubusercontent.com/RumRon/MUSA_508/main/Midterm/geojson/MedicalFacilities.geojson') %>%
  st_transform('EPSG:2264')
# park
cmpd_park<-
  st_read('https://raw.githubusercontent.com/RumRon/MUSA_508/main/Midterm/geojson/Park_Locations.geojson') %>%
  st_transform('EPSG:2264')
# police
cmpd_police<-
  st_read('https://raw.githubusercontent.com/RumRon/MUSA_508/main/Midterm/geojson/CMPD_Police_Offices.geojson') %>%
  st_transform('EPSG:2264')

# bus
cmpd_busstation<-
  st_read('https://raw.githubusercontent.com/RumRon/MUSA_508/main/Midterm/geojson/CATS_BusStops.geojson') %>%
  st_transform('EPSG:2264')

```



```{r turn to sf}

police.sf <-
  cmpd_police %>%
    dplyr::select(name) %>%
    #na.omit() %>%
    st_zm(drop = TRUE) %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = "EPSG:2264") %>%
    st_transform('EPSG:2264') %>%
    distinct()

bus.sf<-
  cmpd_busstation %>%
    dplyr::select(StopID) %>%
    na.omit() %>%
    st_zm(drop = TRUE) %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = "EPSG:2264") %>%
    st_transform('EPSG:2264') %>%
    distinct()

church.sf<-
  cmpd_church %>%
    dplyr::select(num_parent) %>%
    #na.omit() %>%
    st_zm(drop = TRUE) %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = "EPSG:2264") %>%
    st_transform('EPSG:2264') %>%
    distinct()


firestation.sf<-
  cmpd_firestation %>%
    dplyr::select(NAME) %>%
    #na.omit() %>%
    st_zm(drop = TRUE) %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = "EPSG:2264") %>%
    st_transform('EPSG:2264') %>%
    distinct()

medical.sf<-
  cmpd_medical %>%
    dplyr::select(Name) %>%
    #na.omit() %>%
    st_zm(drop = TRUE) %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = "EPSG:2264") %>%
    st_transform('EPSG:2264') %>%
    distinct()

park.sf<-
  cmpd_park %>%
    dplyr::select(prkname) %>%
    #na.omit() %>%
    st_zm(drop = TRUE) %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = "EPSG:2264") %>%
    st_transform('EPSG:2264') %>%
    distinct()

school.sf<-
  cmpd_school %>%
    dplyr::select(school) %>%
    #na.omit() %>%
    st_zm(drop = TRUE) %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = "EPSG:2264") %>%
    st_transform('EPSG:2264') %>%
    distinct()


```



```{r to_k}
mklb.sf <-
  mklb.sf %>%
    mutate(
      police_nn1 = nn_function(st_coordinates(mklb.sf),
                               st_coordinates(police.sf),k=1)
    )
                              
```


```{r read tracts}
# ggplot, reorder
acs_variable_list.20 <- load_variables(2020, #year
                                         "acs5", #five year ACS estimates
                                         cache = TRUE)
tracts20 <- 
  get_acs(geography = "tract", variables = c("B25026_001E","B02001_002E","B15001_050E",
                                             "B15001_009E","B19013_001E","B25058_001E",
                                             "B06012_002E","B28010_007E","B08101_001E",
                                             "B09001_001E","B09001_003E","B09021_002E",
                                             "B11001I_001E", "B14001_009E",
                                             "B17001_002E","B27001_001E","B18101_001E",
                                             "B19001_001E","B25001_001E","B25040_001E"), 
          year=2020, state=37, county=119, geometry=T, output="wide") %>%
  st_transform('EPSG:2264') %>%
  rename(TotalPop = B25026_001E, 
         Whites = B02001_002E,
         FemaleBachelors = B15001_050E, 
         MaleBachelors = B15001_009E,
         MedHHInc = B19013_001E, 
         MedRent = B25058_001E,
         TotalPoverty = B06012_002E,
         Nocom = B28010_007E, 
         Waytowork = B08101_001E,
         Popunder18 = B09001_001E, 
         Popunder3 = B09001_003E,
         Singleadult = B09021_002E, 
         Householdtype = B11001I_001E,
         Addmittogra = B14001_009E,
         Poverty  = B17001_002E,
         Healthins  = B27001_001E,
         Disable  = B18101_001E,
         Familyincome  = B19001_001E,
         Housingunits  = B25001_001E,
         Househeatingfuel  = B25040_001E)%>%
  mutate(pctWhite = ifelse(TotalPop > 0, Whites / TotalPop,0),
         pctBachelors = ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop),0),
         pctPoverty = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0),
         year = "2020") 

```



```{r police_density, echo=FALSE}
## Plot density
ggplot() + geom_sf(data = tracts20, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(police.sf)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = "none") +
  labs(title = "Density") +
  mapTheme()
```



# Introduction
Zillow has realized that its housing market predictions are not as accurate as they could be because they do not factor in enough local intelligence. As such they have asked us to build a better predictive model of home prices for Mecklenberg County, NC.
This model aims to build an accurate and generalizable hedonic model that predicts home prices for Mecklenberg County, NC by deconstructing overall home price into the value of constituent parts. Accurate models lead to only small differences between the predicted and observed values, and generalizable models accurately predict on new data and with comparable accuracy across various groups. By working to improve the accuracy and generalizability of the predictive model, we are ultimately striving to create a more useful decision-making tool. Such a model may be useful for local governments as they assess property taxes, for example.
## Summary Statistics
```{r echo=TRUE}
star_data <- st_drop_geometry(mklb.sf)

stargazer(star_data, type = "text", 
          title = "Table DATA 2.1 Summary Statistics of Internal Characteristics ",
          header = FALSE,
          #out = "try.html",
          single.row = TRUE)
```
          
          
          
Present a table of summary statistics with variable descriptions. 
Sort these variables by their category (internal characteristics, amenities/public services or spatial structure). Check out the `stargazer` package for this.
## Correlation Matrix
Present a correlation matrix

## Home prices scatterplots
Present 4 home price correlation scatterplots that you think are of interest. I’m going to look for interesting open data that you’ve integrated with the home sale observations.
## Map Home Prices
Develop 1 map of your dependent variable (sale price)
## 3 interesting maps
Develop 3 maps of 3 of your most interesting independent variables.
```{r g_symbol_map_population,warning = FALSE, message = FALSE}
# Generate point centers
house_Buffers <-
  rbind(
    st_buffer(mklb.sf, 2640) %>% # 0.25mile = 1320 ft is an acceptable walking distance
      mutate(Legend = "Buffer",count = 1) %>%
      dplyr::select(commonpid, count))

buffer_info <- 
  st_intersection(house_Buffers, bus.sf) %>%
  dplyr::select(commonpid, count)
  

buffer_final <- buffer_info %>%
  group_by(commonpid) #%>%
  summarize("TotalBus" = sum(count))

centers <- st_centroid(buffer_final)
# Set size parameter and the size range for population
ggplot() + 
  geom_sf(data = tracts20, fill = "white") + 
  geom_sf(data = centers, aes(size = TotalBus,fill = TotalBus,alpha = 1),shape = 21, 
          show.legend = "point") + 
  labs(title = "Graduated Symbol Maps of Bus within 0.5 Mile of Each House unit", 
       #subtitle = "San Francisco, CA",
       caption="Figure 1.1") +
  guides(alpha = FALSE)+
  guides(size = FALSE)+
  scale_fill_viridis_c() +
  facet_wrap(~year)+
  geom_sf(data = bus.sf, size = 0.4) +
  scale_size_continuous(range = c(0.1, 15))
```

```{r}

buffer_rbind<-
  st_drop_geometry(buffer_final) 

testtest <- rbind.fill(mklb.sf, buffer_rbind) %>%
  mutate_all(~replace(., is.na(.), 0))
```


## This criterion is linked to a Learning OutcomeBonus for something extra engaging
Include any other maps/graphs/charts you think might be of interest.

# Methods

```{r echo=TRUE}
topredict <-
  mklb.sf%>%
  filter(toPredict!="CHALLENGE")

topredict_num <-
  select_if(st_drop_geometry(topredict), is.numeric) %>% na.omit() 

challenge <-
  mklb.sf%>%
  filter(toPredict=="CHALLENGE")

challenge_num<-
  select_if(st_drop_geometry(challenge), is.numeric) %>% na.omit()  
```

```{r }
# Mapping data
ggplot() +
  geom_sf(data = st_union(tracts20), fill = "grey50") +
   geom_sf(data = topredict, aes(colour = (prisqft)), 
          show.legend = "point", size = .25) +
  scale_fill_viridis_c() +
  labs(title="try") +
  mapTheme()
```




## Table of results (training set)

## Table of goodness of fit (test set)

## CV Results

## Pred vs Obs Scatterplot

## Residuals Map w/ Moran's I

## Predicted Map (Test Set)

## MAPE map by neighborhood

## Scatterplot - MAPE by neighborhood mean price

## Split by Census Groups

# Discussion
Is this an effective model? What were some of the more interesting variables?  How much of the variation in prices could you predict? Describe the more important features? Describe the error in your predictions?  According to your maps, could you account the spatial variation in prices?  Where did the model predict particularly well? Poorly? Why do you think this might be?
## Accuracy

## Generalizability

# Conclusion
Would you recommend your model to Zillow? Why or why not? How might you improve this model? 



